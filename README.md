# DeepSteal: rowhammer-based side channel for ML model weight stealing   
[![GitHub contributors](https://img.shields.io/github/contributors/casrl/deepsteal-exploit.svg)](https://GitHub.com/casrl/deepsteal-exploit/graphs/contributors/) [![Linux](https://badgen.net/static/os/linux/red)](https://badgen.net/static/os/Linux/red) [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-brightgreen.svg)](https://GitHub.com/casrl/deepsteal-exploit/graphs/commit-activity) [![Language](https://img.shields.io/badge/Made%20with-C/C++-1f425f.svg)]([https://isocpp.org/std/the-standard](https://img.shields.io/badge/Made%20with-C/C++-1f425f.svg)) [![GitHub license](https://badgen.net/github/license/casrl/deepsteal-exploit)](https://github.com/casrl/deepsteal-exploit/blob/master/LICENSE.md) 

[![DOI:10.1109/SP46214.2022.00122](https://zenodo.org/badge/DOI/10.1109/SP46214.2022.00122.svg)](https://doi.org/10.1109/SP46214.2022.00122) [![Paper](https://img.shields.io/badge/Paper%20in-IEEE%20S&P%202022-red.svg)](https://www.computer.org/csdl/proceedings-article/sp/2022/131600b551/1CIO7YbAcco)

DeepSteal demonstrates a **digital side channel that can steal fine-grained machine learning model weight information**, which enables subsequent **advanced DNN model extractions**.
At its core, DeepSteal leverages the memory **rowhammer vulnerability** as an *information leakage attack vector* that effectively exfiltrates fined-grained (but partial) **model weight bits** in bulk. DeepSteal then utilizes such partially-revealed model parameters to build extremely powerful model extraction attacks for deep neural networks (DNNs), including the **construction of substitute models** with **superior accuracy and fidelity** as well as enhanced **adversarial input attacks with close to white-box attack performance**. In contrast to previous physical/microarchitecture attacks that leak DNN model hyperparameters or model architectures, DeepSteal unveils a more severe ML privacy concern of ML weight due to HW threats.

This repository contains code for the DeepSteal *system-level exploits*. Specifically, it includes tools to profile DRAMs to identify memory cells (bits) in DRAM DIMMS that are highly reliable and leakable (using rowhammer as a side channel). The repo also contains a proof-of-concept code example that can be used to leak ML model weight bits (HammerLeak) as proposed in the paper.


## Environment
- **Operating System:** Ubuntu 20.04.4 LTS
- **Kernel:** 5.13.0-40-generic
- **GCC:** Ubuntu 9.4.0-1ubuntu1~20.04.1
- **Python:** 3.9.7 (Anaconda distribution)
- **Pytorch:** Source compiled (Tag: v1.7.1-rc3, FBGEMM commit: 1d71039)

## Repository overview  
- **rh_leakage_tool**
  - contains a tool that profiles DRAM to identify *leakable DRAM cells* for rowhammer side channel exploit.
- **system_exploit**
  - attacker
    - Attacker proof-of-concept exploit for machine learning inference server (currently demonstrated on PyTorch)
  - victim
    - Example PyTorch inference server (adapted from: https://pytorch.org/tutorials/advanced/cpp_export.html)
- **dram-addressing-db.md**: a list of DRAM addressing functions we reverse-engineered for Intel processors.
- **utils**

More information about DeepSteal can be found in our [paper](https://casrl.ece.ucf.edu/wp-content/uploads/2021/11/deep-steal-sp.pdf) in IEEE Symposium on Security and Privacy, 2022. Our work can be cited using the following information.

## Citing our paper  
```bibtex
@inproceedings{deepsteal,
  title={Deepsteal: Advanced model extractions leveraging efficient weight stealing in memories},
  author={Rakin, Adnan Siraj* and Chowdhuryy, Md Hafizul Islam* and Yao, Fan and Fan, Deliang},
  booktitle={IEEE Symposium on Security and Privacy (S&P)},
  year={2022},
  organization={IEEE}
}
```
