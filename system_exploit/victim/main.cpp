#include <torch/script.h> // One-stop header.

#include <iostream>
#include <memory>
#include "ATen/Parallel.h"

#include <fstream>
#include <sstream>
#include <iostream>
#include <string>
#include <sys/stat.h>
#include <filesystem>

int main(int argc, const char* argv[]) {
  at::set_num_threads(1);
  if (argc != 2) {
    std::cerr << "usage: ./main <path-to-exported-script-module>\n";
    return -1;
  }
  torch::jit::script::Module module;
  try {
    module = torch::jit::load(argv[1]);
  }
  catch (const c10::Error& e) {
    std::cerr << "error loading the model\n";
    return -1;
  }
  std::cout << "Model loaded\nWaiting for inference\n\n" << std::endl;

  // Create a vector of inputs.
  std::vector<torch::jit::IValue> inputs;
  at::set_num_threads(1);

  int repeat = 1;
  int idx = 0;
  while (repeat) {
    char test[10];
    char response;
    std::cout << "Enter Y to proceed to next infer: ";
    std::cin >> response;
    if (!( response != 'Y' && response != 'y')) {
      inputs.clear();
      inputs.push_back(torch::randn({64, 3, 32, 32}));
      printf("Starting inference...\n");
      module.forward(inputs).toTensor();
      printf("completed\n\n");
    } else repeat = 0;
  }
}
