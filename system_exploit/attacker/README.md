# DeepSteal system-level exploit

This directory contains the exploitation tool for DeepSteal system-level exploit (using FBGEMM backend with quantized model).

## Description of the DeepSteal system-level exploitation utility
This repo includes example implementation of several key techniques used in DeepSteal to enable efficient exfiltration of ML model weight bits in bulk. At a high level, this code shows an example attack with the following components:
- **Utilization of column-wise data dependence** in rowhammer bit flip to infer memory bits with a **flexible rowhammer memory layout** for leakage.
- **Victim execution anchoring** using cache side channel to track/predict victim's secretive page (e.g., model weight pages) allocations/accesses in chunks.
- **Batched page release** that enables memory massaging for a large number of victim's pages in smaller batches to achieve high page relocation accuracy.
- **Anonymous page swapping** that reshuffles the physical page locations for victim pages so that different bits within the same page can be leaked through an iterative process.

Note: in order to map a leaked bit in within a physical page to the logic weight bit, it is necessary to figure out how consecutive weights are organized in memory, which may differ across platforms. The current mapping is based on pytorch with the FBGEMM backend. More details can be found in the paper.

## Environment
- **Operating System:** Ubuntu 20.04.4 LTS
- **Kernel:** 5.13.0-40-generic
- **GCC:** Ubuntu 9.4.0-1ubuntu1~20.04.1
- **Python:** 3.9.7 (Anaconda distribution)
- **Pytorch:** Source compiled (Tag: v1.7.1-rc3, FBGEMM commit: 1d71039)


## Steps to run

### Setup
- Compile Pytorch from source (https://github.com/pytorch/pytorch/tree/v1.7.1-rc3)
- In **main.c**
    - Replace <em>path_to_libtorch_cpu.so</em> with <em>$pytorch_directory/torch/libtorch_cpu.so</em>
    - Replace <em>path_to_bitflip_profile</em> with bifflip profile file
- Install Mastik toolkit (https://github.com/0xADE1A1DE/Mastik, also available in <em>utils/Mastik</em> in this repository).
- Compile the attacker code by running <code>make</code>

### Exploitation
- Run victim inference process: <code>taskset 0x1 ../victim/build/main path_to_model</code>
- Run the example attack process: <code>taskset 0x1 ./main</code>
- The attack process initializes, monitors the ML inference execution and performs the attack.
- The output will be save in <em>output.dat</em>. This file contains the physical addresses of the victim model weight pages. Use this with rowhammer leakage to recover weight bits.
- **Note**: this example relies on access to <em>pagemap</em> to map virtual addresses to physical addresses, which may need a sudo.
