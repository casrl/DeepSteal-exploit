#include <linux/perf_event.h>
#include <linux/hw_breakpoint.h>
#include <sys/ioctl.h>
#include <asm/unistd.h>
#include <assert.h>
#include <errno.h>
#include <inttypes.h>
#include <fcntl.h>
#include <linux/kernel-page-flags.h>
#include <map>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mount.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <sys/wait.h>
#include <time.h>
#include <unistd.h>
#include <vector>
#include <set>
#include <iostream>
#include <fstream>
#include <sstream>
#include <utility>
#include "rh_util.h"
#include "dram_sys.h"

//namespace {

// for debugging
//#define MEASURE_EVICTION
//#define MULTIPLE_TRIES
//#define DEBUG_PROFILE
/*#define TEST_SINGLE_ROW*/

//#define TEST_HAMMER_TIME

//#define FREQ_THD 3 //frequency threshold for bit profile
int freq_thd; //frequency threshold for bit profile

// The fraction of physical memory that should be mapped for testing.
double fraction_of_physical_memory = 0.4;

// The number of memory reads to try.
#define NUMBER_OF_READS (2*1000*1000)
uint64_t number_of_reads = NUMBER_OF_READS;

size_t phy_mem = 4;

static ssize_t ROW_SIZE; // bytes for rows with same row number

static uint64_t pages_in_row = 0;

uint64_t goal = 0ULL;//goal 0: 1->0, goal 1: 0->1

int random_page = 0;

bool random_content = false;

int total_tries = 8;

uint64_t target_pa_set = 0;

int verbose = 0;

std::string content_filename;

int page_index;//page index from content file

//int d_pattern = 0; //0: row striping; 1: column only (precise); 2: leakage test

uint64_t mapping_size;


HASH_ROW_PAGES_T hash_row_pages;

std::map<uint64_t, std::map<int, int>> page_offsets0; //page number: (offset, frequency) 1->0
std::map<uint64_t, std::map<int, int>> page_offsets1; //page number: (offset, frequency) 0->1

std::map<int, std::vector<uint64_t>> offset_pages_map0;
std::map<int, std::vector<uint64_t>> offset_pages_map1;


void load_page_offsets(std::string profile, 
  std::map<uint64_t, std::map<int, int>>& p_offsets, 
  std::map<int, std::vector<uint64_t>>& offset_pages_map){
  std::ifstream flip_file;
  flip_file.open(profile.c_str());

  //fprintf(stdout, "load bit profile file\n");
  if(flip_file.is_open()){
    std::string line;
    while(std::getline(flip_file, line)){
      if(line.at(0) == '#' || line.at(0) == '\n')
        continue;
      else{
        std::istringstream iss(line);
        uint64_t pa; iss >> std::hex >> pa;
        uint64_t tmp; iss >> tmp;//this is the mode

        int offset;
        int freq;
        iss >> std::dec;
        while(iss >> offset){
          iss >> freq;
          //this is hard coded since the bit profile  was collected with -t 4
          if(freq <= 3)
            continue;
          p_offsets[pa][offset] = freq;
          offset_pages_map[offset].push_back(pa);
          //printf("offset is:%d\n", offset);
        }

      }

    }

    printf("%zu lines read from %s\n", p_offsets.size(), profile.c_str());
#ifdef DEBUG_PROFILE
    for(auto entry: p_offsets){
      printf("page num: 0x%lx: ", entry.first);
      for(auto sub_entry: entry.second){
        printf("(%d, %d) ", sub_entry.first, sub_entry.second);
      }
      printf("\n");
    }
    exit(0);
#endif
  }
  else{
    fprintf(stdout, "cannot open file %s\n", profile.c_str());
    exit(-1);
  }
}

void SetupMapping(uint64_t* mapping_size, void** mapping) {
  // Source: https://github.com/IAIK/rowhammerjs
  uint64_t system_mem_size = GetPhysicalMemorySize();
  fprintf(stdout, "size of memory in pages %lu\n", system_mem_size/4096);

  *mapping_size =
    static_cast<uint64_t>((static_cast<double>(system_mem_size) *
          fraction_of_physical_memory));

  printf("creating %lu pages\n", *mapping_size/4096);

  *mapping = mmap(NULL, *mapping_size, PROT_READ | PROT_WRITE,
      MAP_POPULATE | MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
  assert(*mapping != (void*)-1);

  // Initialize the mapping so that the pages are non-empty.
  //fprintf(stderr,"[!] Initializing large memory mapping ...");
  for (uint64_t index = 0; index < *mapping_size; index += 0x1000) {
    uint64_t* temporary = reinterpret_cast<uint64_t*>(
        static_cast<uint8_t*>(*mapping) + index);
    temporary[0] = index;
  }
  //fprintf(stderr,"done\n");
}

void count_bitflip(uint64_t* target, uint64_t ori, uint32_t index, 
    std::map<int,std::map<int, int>>& indices){
  uint64_t src = target[index];
  uint64_t temp = src ^ ori;
  //int count = 0;
  int offset = 0;
  while(temp){
    //count += temp & 0x1;
    //assume little endian
    if(temp & 0x1){
      int mode;
      if((src & (1UL<<offset)) > 0)
        mode = 1;
      else
        mode = 0;
      indices[mode][offset+index*64] +=1;
    }

    temp >>=1;
    offset++;
  }
}

void HammerThread() {
  return;
}

void dummy(volatile uint64_t* a,volatile uint64_t* b, volatile uint64_t* c, volatile uint64_t* d)
{
  if (a == b && c == d)
    exit(-1);
}


//get the used bits in a data. E.g., 01000 used bits is 4
int get_used_bits(uint64_t data){
  int used_bits = 0;
  while(data != 0){
    data >>= 1;
    used_bits++;
  }

  return used_bits;
}

void gen_random_page(uint64_t* page_addr){
    //printf("filling page with random content\n");
    for (uint32_t index = 0; index < 512; ++index){
     uint64_t data = ((uint64_t)rand()<<32) | ((uint64_t)rand());
      //set the flipped bits to 1 or 0 based on goal
      page_addr[index] = data;
      //content_copy[index] = data;
    }
}

void set_with_template(uint64_t* va_addr, 
  RH_PROFILE_T* live_template, int mode){
  uint8_t* va = (uint8_t*) va_addr;
  int page_offset, byte_index, bit_offset;

  for(auto entry: (*live_template)[mode]){
    page_offset = entry.first;
    byte_index = page_offset/8;
    bit_offset = page_offset%8;

    if(mode == 1)
      va[byte_index] |= 1U<<bit_offset;
    else if(mode == 0)
      va[byte_index] &= 0xFF-(1U<<bit_offset);
  }
}

void set_with_profile(uint64_t* va_addr, uint64_t target_pa, int mode){
  uint8_t* va = (uint8_t*) va_addr;
  int page_offset, byte_index, bit_offset;
  if(mode == 0){
    //set the flippable bits based on the profile0
    for(auto entry: page_offsets0[target_pa]){
      page_offset = entry.first;
      byte_index = page_offset/8;
      bit_offset = page_offset%8;

      va[byte_index] |= 1U<<bit_offset;
    }
  }
  else if(mode == 1){
    //set the flippable bits based on the profile1
    for(auto entry: page_offsets1[target_pa]){
      page_offset = entry.first;
      byte_index = page_offset/8;
      bit_offset = page_offset%8;

      va[byte_index] &= 0xFF-(1U<<bit_offset);
    }
  }
}

void set_victim_content(uint64_t* victim_addr, uint64_t* vic_copy, int goal){
  uint64_t VAL_VIC;
  uint8_t* victim = (uint8_t*) victim_addr;

  // if(random_content){
  //   gen_random_page(victim_addr);
  //   set_with_template(victim_addr, tested_offset_freq, goal, 0);
  // }
  if(!content_filename.empty()){//load content from file
    int content_fd = open(content_filename.c_str(), O_RDONLY);
    if(content_fd == -1){
      printf("could not open content file %s\n", content_filename.c_str());
      exit(-1);
    }

    if(pread(content_fd, (void*)victim_addr, 4096, page_index*4096) != 4096){
      printf("failed to read a page\n");
      exit(-1);
    }
    close(content_fd);

  }
  else{
    VAL_VIC = goal? 0 : (-1ULL);

    printf("victim row content is set to 0x%lx\n", VAL_VIC);
    for (uint32_t index = 0; index < 512; ++index)
        victim_addr[index] = VAL_VIC;
  }

  memcpy((void*)vic_copy, (void*)victim_addr, 4096);
  flush_page(victim_addr);
}


/*set bit for mode at both 1->0 locations and 0->1 locations */
void flip_combine_agg_page(uint64_t target_pa, uint8_t* agg_addr, int mode){

  /*since bit profile may be obsolete, we choose to combine all possible offsets
    for mode 0 and 1 for precise hammering
    */
  //std::map<int, int>& offsets0 = page_offsets0[target_pa];
  std::vector<std::map<int, int>*> offsets_vec;
  offsets_vec.push_back(&page_offsets0[target_pa]);
  offsets_vec.push_back(&page_offsets1[target_pa]);

  for(int i=0; i<2; i++){
    for(auto entry: *(offsets_vec[i])){
      uint64_t page_offset = entry.first;
      int byte_index, bit_offset;
      byte_index = page_offset/8;
      bit_offset = page_offset%8;

      //set the corresponding bit to 0
      uint8_t byte = agg_addr[byte_index];
      if(mode == 0)
        agg_addr[byte_index] &= 0xFF-(1U<<bit_offset);
      else
        agg_addr[byte_index] |= 1U<<bit_offset;
      // printf("Offset: %d Debug: orignal byte: 0x%x, set byte: %x\n", entry.first, 
      //   byte, agg_addr[byte_index]);
    }
  }
}



void flip_agg_page(uint64_t target_pa, uint8_t* agg_addr, int mode){
  if(mode == 0){
    std::map<int, int>& offsets = page_offsets0[target_pa];
    for(auto entry: offsets){
      uint64_t page_offset = entry.first;
      int byte_index, bit_offset;
      byte_index = page_offset/8;
      bit_offset = page_offset%8;

      //set the corresponding bit to 0
      agg_addr[byte_index] &= 0xFF-(1U<<bit_offset);
    }
  }
  else if(mode == 1){
    std::map<int, int>& offsets = page_offsets1[target_pa];
    for(auto entry: offsets){
      uint64_t page_offset = entry.first;
      int byte_index, bit_offset;
      byte_index = page_offset/8;
      bit_offset = page_offset%8;

      //set the corresponding bit to 1
      agg_addr[byte_index] |= 1U<<bit_offset;
    }

  }
}

std::map<int, uint8_t> set_agg_for_leak(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int mode){
  bool gen = false;
  std::map<int, uint8_t> bits_to_leak;

  for(uint8_t* one_addr : hash_row_pages[the_hash_set][the_row]){
    uint64_t* agg_addr = (uint64_t*) one_addr;
    if(!gen){
      gen_random_page(agg_addr);
      gen = true;
    }
    else
      memcpy((void*)agg_addr, (void*)hash_row_pages[the_hash_set][the_row][0], 4096);
    //memset((void*)agg_addr, 1, 4096);

    flush_page(agg_addr);
  }

  uint8_t bit;
  uint8_t* agg_addr = hash_row_pages[the_hash_set][the_row][0];
  
  for(auto entry: (*tested_offset_freq)[mode]){
    int page_offset, byte_index, bit_offset;
    page_offset = entry.first;
    byte_index = page_offset/8;
    bit_offset = page_offset%8;
    bit = (agg_addr[byte_index] & (1U<<bit_offset)) >0? 1: 0;
    bits_to_leak[page_offset] = bit;
  }

  return bits_to_leak;
}

std::map<int, uint8_t>  set_agg_content(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int goal, bool precise){
    uint64_t VAL_AGG = goal? (-1ULL): 0;
    std::map<int, uint8_t> bits_in_agg;
    //only works when one page maps to a single row
    //set value for agg1 and agg2
    //if(precise)
    //  printf("generating random page content for aggressors\n");

    for(uint8_t* one_addr : hash_row_pages[the_hash_set][the_row]){
      uint64_t* agg_addr = (uint64_t*) one_addr;

      if(!precise){
        set_and_flush(agg_addr, VAL_AGG);
      }
      else{
        gen_random_page(agg_addr);
        //TODO: if a page from file is set to the victim, we might want to
        //check the bits that could not be flipped, and do not flip the corresponding
        //bits in aggs
        if(tested_offset_freq== NULL || (*tested_offset_freq)[goal].size() == 0){
          printf("set agg is given null or empty live template\n");
          exit(-1);
        }

        set_with_template(agg_addr, tested_offset_freq, goal);
        //flip_combine_agg_page(target_pa, (uint8_t*)agg_addr, goal);
         flush_page(agg_addr);
      }
    } 

     uint8_t bit;
    // if(hash_row_pages[the_hash_set][the_row].find(0) == hash_row_pages[the_hash_set][the_row].end()){
    //   printf("Debug: victim page not properly found\n");
    //   exit(-1);
    // }

    if(tested_offset_freq != NULL){
      uint8_t* agg_addr = hash_row_pages[the_hash_set][the_row][0];
      for(auto entry: (*tested_offset_freq)[goal]){
        int page_offset, byte_index, bit_offset;
        page_offset = entry.first;
        byte_index = page_offset/8;
        bit_offset = page_offset%8;
        bit = (agg_addr[byte_index] & (1U<<bit_offset)) >0? 1: 0;
        bits_in_agg[page_offset] = bit;
      }
    }

    return bits_in_agg;
}  


bool check_page_hammerable(uint64_t target_pa, uint8_t **victim){

  size_t the_hash_set;
  uint64_t the_row;

  the_hash_set = get_dram_mapping((void*)target_pa);
  the_row = target_pa/ROW_SIZE;

  uint8_t* the_va = 0;
  if(hash_row_pages.find(the_hash_set) != hash_row_pages.end()){
    bool has_pa = false;

    if(hash_row_pages[the_hash_set].find(the_row) != hash_row_pages[the_hash_set].end()){
      for(uint8_t* va: hash_row_pages[the_hash_set][the_row]){
        if(get_physical_addr((uint64_t)va) == target_pa){
          has_pa = true;
          the_va = va;
          break;
        }
      }
    }

    if(!has_pa){
      printf("WARNING: could not find target pa 0x%lx\n", 
        target_pa);
      return false;
    }
    else{
      if(hash_row_pages[the_hash_set].find(the_row-1) != hash_row_pages[the_hash_set].end()
          && hash_row_pages[the_hash_set].find(the_row+1) != hash_row_pages[the_hash_set].end()){
        if(hash_row_pages[the_hash_set][the_row-1].size() != pages_in_row 
            || hash_row_pages[the_hash_set][the_row+1].size() != pages_in_row){
          printf("WARNING: aggressor rows not filled with pages for pa 0x%lx\n", 
            target_pa);
          return false;
        }     
      }
      else{
        printf("WARNING: could not find two aggressors for pa 0x%lx:\n", 
          target_pa);
        return false;
      }
    }

  }
  else{
    printf("WARNING: no target hash_set found in allocated memory pool for pa 0x%lx\n", 
      target_pa);
    return false;
  }

  *victim = the_va;
  return true;

}

void print_flip_template(RH_PROFILE_T& live_template, int goal){
    printf("mode: %d", goal);
    for(auto entry: live_template[goal]){
      printf("%6d,%d ", entry.first, entry.second); //offset,freq
    }
    printf("\n");
}

void print_leak_template(RH_LEAK_T& live_template, int goal){
    printf("mode: %d", goal);
    std::string leak_type;

    for(auto entry: live_template[goal]){
      switch(entry.second){
        case STRONG_XYX: leak_type = "STRONG_XYX"; break;
        case STRONG_XYY: leak_type = "STRONG_XYY"; break;
        case STRONG_YYX: leak_type = "STRONG_YYX"; break;
        case WEAK_XYX_ANY: leak_type = "WEAK_XYX_ANY"; break;
        case WEAK_XYX_UP: leak_type = "WEAK_XYX_UP"; break;
        case WEAK_XYX_LOW: leak_type = "WEAK_XYX_LOW"; break;
        case WEAK_XYY_ANY: leak_type = "WEAK_XYY_ANY"; break;
        //case WEAK_XYY_UP: leak_type = "WEAK_XYY_UP"; break;
        case WEAK_XYY_LOW: leak_type = "WEAK_XYY_LOW"; break;
        case WEAK_YYX_ANY: leak_type = "WEAK_YYX_ANY"; break;
        case WEAK_YYX_UP: leak_type = "WEAK_YYX_UP"; break;
        //case WEAK_YYX_LOW: leak_type = "WEAK_YYX_LOW"; break;

        default: leak_type = "UNEXPECTED";
      }
      printf("%6d,%s ", entry.first, leak_type.c_str()); //offset,LEAK_TYPE
    }
    printf("\n");
}

//find a random page there is hammerable
uint64_t find_hammerable_page(uint8_t **victim, int mode){

  std::map<uint64_t, std::map<int, int>>* page_offsets;
  page_offsets = !mode ? (&page_offsets0) : (&page_offsets1);

  size_t the_offset; uint64_t r_address = 0;

  do{
    the_offset = rand()%page_offsets->size();
    auto iter = std::next(page_offsets->begin(), the_offset);
    r_address = iter->first;
  }while(!check_page_hammerable(r_address, victim) && printf("page 0x%lx not ready for hammering\n", r_address));
  
  // while(!check_page_hammerable(r_address, victim)){
  //   printf("page 0x%lx not ready for hammering\n", r_address);

  //   the_offset = rand()%page_offsets->size();
  //   auto iter = std::next(page_offsets->begin(), the_offset);
  //   r_address = iter->first;
  // }

  return r_address;
}

// A comprehensive test that attempts to hammer adjacent rows for a given
// assumed row size (and assumptions of sequential physical addresses for
// various rows.
void HammerTargetPages(HammerFunction* hammer, uint64_t* victim_addr, uint64_t target_addr,  uint64_t number_of_reads, 
    std::map<int, std::map<int, int>>& tested_offset_freq, uint64_t* content_copy) {
  uint64_t total_bitflips = 0;
  // uint8_t *victim;
  size_t the_hash_set;
  uint64_t the_row;


  uint64_t target_pa = target_addr;
 
  the_hash_set = get_dram_mapping((void*)target_pa);
  the_row = target_pa/ROW_SIZE;

  //printf("starting testing for %d times\n", total_tries);

  uint8_t* agg1 = hash_row_pages[the_hash_set][the_row-1][0];
  uint8_t* agg2 = hash_row_pages[the_hash_set][the_row+1][0];
  assert(agg1 && agg2);
  printf("testing pa: 0x%lx at row: %zu, hash_set: %zu with agg1: 0x%lx and agg2: 0x%lx\n", 
    target_pa, the_row, the_hash_set, get_physical_addr((uint64_t)agg1), 
  get_physical_addr((uint64_t)agg2));

  uint64_t* agg1_addr = (uint64_t*) agg1;
  uint64_t* agg2_addr = (uint64_t*) agg2; 

  //in this version the first_row_page may not be page-aligned
  std::pair<uint64_t, uint64_t> first_page_range(
    reinterpret_cast<uint64_t>(agg1),
    reinterpret_cast<uint64_t>(agg1+0x1000));
  std::pair<uint64_t, uint64_t> second_page_range(
    reinterpret_cast<uint64_t>(agg2),
    reinterpret_cast<uint64_t>(agg2+0x1000));

  
  // set_agg_content(the_hash_set, the_row-1,
  //     target_pa, goal, precise);

  // set_agg_content(the_hash_set, the_row+1,
  //     target_pa, goal, precise);

  for (size_t tries = 0; tries < total_tries; ++tries){
    if(verbose > 2)
      printf("hammering the target page, attempt #%zu\n", tries);
    hammer(first_page_range, second_page_range, number_of_reads);
    
    // Now check the target pages.
    for (uint32_t index = 0; index < 512; ++index) {
      if (victim_addr[index] != content_copy[index]) {
        count_bitflip(victim_addr, content_copy[index], index, tested_offset_freq); 
        //bit_flips_in_page += indices.size();
        //offset start from -1 to distinguish it from user specified offerset

        if(verbose > 2){
          fprintf(stdout,"[!] Hashset %zu: flip (0x%016lx != 0x%016lx) in (pa 0x%lx, vpn 0x%lx, index %u) at row %zu "
              "when hammering with (pa 0x%lx, va 0x%lx) at row %zu and (pa 0x%lx, va 0x%lx) at row %zu\n", 
              the_hash_set, victim_addr[index], content_copy[index],
              get_physical_addr((uint64_t)victim_addr), (uint64_t)victim_addr, index, the_row+1, 
              get_physical_addr((uint64_t)agg1_addr), (uint64_t)agg1_addr, the_row, 
              get_physical_addr((uint64_t)agg2_addr), (uint64_t)agg2_addr, the_row+2);
        }
      }

    }

    //reset content of target page
    memcpy((void*)victim_addr, (void*)content_copy, 4096);
    flush_page((uint64_t*)victim_addr);

    for(auto entry: tested_offset_freq){
      if(verbose > 2)
        fprintf(stdout, "Found %zu flips with mode %d at row %zu\n", 
          entry.second.size(), entry.first, the_row);
    }
  }

  // printf("bit flip summary:\n");
  // printf("profile0:");

  // //std::map<int, int>& offset_freq = page_offsets[target_pa];
  // for(auto entry : page_offsets0[target_pa]){
  //   printf("%6d,%d ", entry.first, entry.second); //offset,freq
  // }
  // printf("\n");

  // printf("profile1:");

  // //std::map<int, int>& offset_freq = page_offsets[target_pa];
  // for(auto entry : page_offsets1[target_pa]){
  //   printf("%6d,%d ", entry.first, entry.second); //offset,freq
  // }
  // printf("\n");  


  // if(!tested_offset_freq.size()){//no bit flip detected
  //   printf("NO BIT FLIP FOUND\n");
  // }
  // else{
  //   printf("hammer result: ");
  //   for(auto entry: tested_offset_freq){
  //     int mode = entry.first;
  //     printf("mode: %d", mode);
  //     for(auto sub_entry : entry.second){
  //       printf("%6d,%d ", sub_entry.first, sub_entry.second); //offset,freq
  //     }
  //     printf("\n");
  //   }
  //   //print_flip_template(tested_offset_freq);
  // }

}//end of function

void set_content_XYX(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int goal, bool precise){
  set_agg_content(the_hash_set, the_row-1, tested_offset_freq, goal, precise);
  set_agg_content(the_hash_set, the_row+1, tested_offset_freq, goal, precise);
}

void set_content_YYX(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int goal, bool precise){
  set_agg_content(the_hash_set, the_row-1, tested_offset_freq, goal^1, precise);
  set_agg_content(the_hash_set, the_row+1, tested_offset_freq, goal, precise);
}

void set_content_XYY(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int goal, bool precise){
  set_agg_content(the_hash_set, the_row-1, tested_offset_freq, goal, precise);
  set_agg_content(the_hash_set, the_row+1, tested_offset_freq, goal^1, precise);
}


void set_content_YYY(size_t the_hash_set, uint64_t the_row, 
  RH_PROFILE_T* tested_offset_freq, int goal, bool precise){
  set_agg_content(the_hash_set, the_row-1, tested_offset_freq, goal^1, precise);
  set_agg_content(the_hash_set, the_row+1, tested_offset_freq, goal^1, precise);
}


RH_LEAK_T set_leaky_template(RH_PROFILE_T& XYX, RH_PROFILE_T& YYX, RH_PROFILE_T& XYY, 
  RH_PROFILE_T& YYY, RH_PROFILE_T& target, int goal){
  RH_LEAK_T mode_offset_lt;

  int page_offset;
  for(auto entry: XYX[goal]){
    page_offset = entry.first;
    //filter out the non-repetitive ones
    if(entry.second >= freq_thd)
      mode_offset_lt[goal][page_offset] = UNEXPECTED;
  }

  for(auto entry: YYX[goal]){
    page_offset = entry.first;
    if(entry.second >= freq_thd)
      mode_offset_lt[goal][page_offset] = UNEXPECTED;
  }

  for(auto entry: XYY[goal]){
    page_offset = entry.first;
    if(entry.second >= freq_thd)
      mode_offset_lt[goal][page_offset] = UNEXPECTED;
  }

  for(auto entry: YYY[goal]){
    page_offset = entry.first;
    if(entry.second >= freq_thd)
      mode_offset_lt[goal][page_offset] = UNEXPECTED;
  }

  //printf("FY %d %d\n", WEAK_LHL, UNEXPECTED);

  #define TEST_YES(X) ((X)[goal].find(page_offset) != (X)[goal].end())
  #define TEST_NO(X) ((X)[goal].find(page_offset) == (X)[goal].end())
  #define CHECK(A, B, C, D) (TEST_##A(XYX) && TEST_##B(YYX) && TEST_##C(XYY) && TEST_##D(YYY))

  for(auto entry: mode_offset_lt[goal]){
    page_offset = entry.first;

    if(CHECK(YES, NO, NO, NO)){//0b1000
      mode_offset_lt[goal][page_offset] = STRONG_XYX;
    }
    else if(CHECK(NO, NO, YES, NO)){//0b0010
      mode_offset_lt[goal][page_offset] = STRONG_XYY;
    }
    else if(CHECK(NO, YES, NO, NO)){//0b0100
      mode_offset_lt[goal][page_offset] = STRONG_YYX;
    }
    else if(CHECK(YES, YES, YES, NO)){//0b1110
      mode_offset_lt[goal][page_offset] = WEAK_XYX_ANY;
    }
    else if(CHECK(YES, NO, YES, NO)){//0b1010 //1
      mode_offset_lt[goal][page_offset] = WEAK_XYX_UP; 
    }
    else if(CHECK(YES, YES, NO, NO)){//0b1100 //2
      mode_offset_lt[goal][page_offset] = WEAK_XYX_LOW; 
    }
    else if(CHECK(YES, NO, YES, YES)){//0b1011
      mode_offset_lt[goal][page_offset] = WEAK_XYY_ANY;
    }
    // else if(CHECK(YES, NO, YES, NO)){//0b1010
    //   mode_offset_lt[goal][page_offset] = WEAK_XYY_UP; //redundant 1
    // }
    else if(CHECK(NO, NO, YES, YES)){//0b0011
      mode_offset_lt[goal][page_offset] = WEAK_XYY_LOW;
    }
    else if(CHECK(YES, YES, NO, YES)){//0b1101
      mode_offset_lt[goal][page_offset] = WEAK_YYX_ANY;
    }
    else if(CHECK(NO, YES, NO, YES)){//0b0101
      mode_offset_lt[goal][page_offset] = WEAK_YYX_UP;
    }
    // else if(CHECK(YES, YES, NO, NO)){//0b1100 //redundant 2
    //   mode_offset_lt[goal][page_offset] = WEAK_YYX_LOW; 
    // }

    // //printf("Testing offset %d\n", page_offset);
    // if(XYX[goal].find(page_offset) != XYX[goal].end() && YYX[goal].find(page_offset) == YYX[goal].end() 
    //   && XYY[goal].find(page_offset) == XYY[goal].end() && YYY[goal].find(page_offset) == YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = STRONG_LHL;
    //   //printf("Offset %d is Strong_LHL\n", page_offset);
    // }

    // else if(XYX[goal].find(page_offset) == XYX[goal].end() && YYX[goal].find(page_offset) == YYX[goal].end() 
    //   && XYY[goal].find(page_offset) != XYY[goal].end() && YYY[goal].find(page_offset) == YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = STRONG_HHL;
    //   //printf("Offset %d is Strong_HHL\n", page_offset);
    // }

    // else if(XYX[goal].find(page_offset) == XYX[goal].end() && YYX[goal].find(page_offset) != YYX[goal].end() 
    //   && XYY[goal].find(page_offset) == XYY[goal].end() && YYY[goal].find(page_offset) == YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = STRONG_LHH;
    //   //printf("Offset %d is Strong_LHH\n", page_offset);
    // }

    // else if(XYX[goal].find(page_offset) != XYX[goal].end() && YYX[goal].find(page_offset) != YYX[goal].end() 
    //   && XYY[goal].find(page_offset) != XYY[goal].end() && YYY[goal].find(page_offset) == YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = WEAK_LHL;
    //   //printf("Offset %d is Weak_LHL\n", page_offset);
    // }

    // else if(XYX[goal].find(page_offset) != XYX[goal].end() && YYX[goal].find(page_offset) == YYX[goal].end() 
    //   && XYY[goal].find(page_offset) != XYY[goal].end() && YYY[goal].find(page_offset) != YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = WEAK_HHL;
    //   //printf("Offset %d is Weak_HHL\n", page_offset);
    // }

    // else if(XYX[goal].find(page_offset) != XYX[goal].end() && YYX[goal].find(page_offset) != YYX[goal].end() 
    //   && XYY[goal].find(page_offset) == XYY[goal].end() && YYY[goal].find(page_offset) != YYY[goal].end()){
    //   mode_offset_lt[goal][page_offset] = WEAK_LHH;
    //   //printf("Offset %d is Weak_LHH\n", page_offset);
    // }
  }

  print_leak_template(mode_offset_lt, goal);
  /*consider the following bit type to be leakable: STRONG_XYX, (STRONG_YYX), WEAK_XYX_UP, WEAK_XYY_ANY, 
    (WEAK_YYX_UP). No modeling the leaky one where the guessed bit needs negation.
  */

  for(auto entry: mode_offset_lt[goal]){
    page_offset = entry.first;
    if(entry.second == STRONG_XYX || entry.second == WEAK_XYX_UP || entry.second == WEAK_XYY_ANY)
    //if(entry.second == STRONG_XYX )
      target[goal][page_offset] = XYX[goal][page_offset];
  }

  return mode_offset_lt;

}

int count_bits_leaked(std::map<int, uint8_t>& bits_top_agg, 
  RH_PROFILE_T& mode_offset_freq, int mode){
  int bits_leaked = 0;
  bool flipped;
  for(auto entry: bits_top_agg){
    int page_offset = entry.first;
    uint8_t sec_bit = entry.second;

    if(mode_offset_freq[mode].find(page_offset) != mode_offset_freq[mode].end())
      flipped = true;
    else
      flipped = false;  

    if((mode == (int)sec_bit) && flipped) bits_leaked++;
    else if((mode != (int)sec_bit) && !flipped) bits_leaked++;;
  }

  return bits_leaked;
}

int main(int argc, char** argv) {
  // Turn off stdout buffering when it is a pipe.
  setvbuf(stdout, NULL, _IONBF, 0);

  std::string bitflip_profile0;
  std::string bitflip_profile1;
  std::string retest_bp_file;
  uint64_t target_address = 0;
  //if turn on, this will remove non-leaky bits from live template
  //bool optimize = false; 

  int per_page_iteration = 1; //iterations to test leakgage of a bit
  int opt;
  while ((opt = getopt(argc, argv, "t:p:c:d:m:g:i:j:a:r:T:V:f:P:F:I:O")) != -1) {
    switch (opt) {
      case 't':
        total_tries = atoi(optarg);
        freq_thd = 0.8*total_tries;
        break;
      case 'p':
        fraction_of_physical_memory = atof(optarg);
        break;
      case 'd':
        init_dram_config(atoi(optarg));
        break; 
      case 'm':
        phy_mem = atoi(optarg);
        break;
      case 'g'://0:1->0; 1:0->1; 2:both
        goal = (uint64_t)atoi(optarg);
        break;
      case 'i'://bit profile 0
        bitflip_profile0 = std::string(optarg);
        break;  
      case 'j'://bit profile 1
        bitflip_profile1 = std::string(optarg);
        break;    
      case 'r':
        random_page = atoi(optarg);
        break;
      // case 'R':
      //   random_content = true;  
      //   break;  
      // case 'O':
      //   optimize = true;  
      //   break;      
      case 'T':
        number_of_reads = (uint64_t)(atof(optarg)*1000*1000);   
        break;    
      case 'V':
        verbose = atoi(optarg);
        break;     
      // case 'C':
      //   precise_hammer = true;
      //   break;   
      case 'I':
        per_page_iteration = atoi(optarg);
        printf("each page will be tested for leakage with %d times\n", per_page_iteration);
        break;   
      case 'F':
        retest_bp_file = std::string(optarg);
        printf("retesting bit flips based on bits offets in file %s\n", 
          optarg);
        break;    
      case 'a':{
                 //std::istringstream iss(std::string("0x11"));
                 std::string tmp(optarg);
                 std::istringstream iss(tmp);
                 iss >> std::hex >> target_address;
                 printf("targeted pa: %lx\n", target_address);
                 break;   
               }
      case 'f':
        content_filename = std::string(optarg);
        break;
      case 'P':
        page_index = atoi(optarg);
        break;
      default:
         fprintf(stderr, "Usage: %s [-t number of tests] [-p percent] "
             " [-r random page] [-m phy_memory_in_gigs] [-g goal (1|0)]"
             "[-i bit profile path] [-a target address to hammer (in hex)]"
             "[-T number of reads for each hammer term (x Millions)]"
             "[-V verbose level] [-f page content file] [-F file bit offset for retest] "
             "[-P page index]""\n",
             argv[0]);
         exit(EXIT_FAILURE);
    }
  }

  printf("number of reads set to %lu\n", number_of_reads);
  
  ROW_SIZE = get_row_size();
  pages_in_row = get_pages_in_row();

  signal (SIGINT, force_exit);

  printf("load mode 0 bitflip profile\n");
  load_page_offsets(bitflip_profile0, page_offsets0, offset_pages_map0);
  printf("load mode 1 bitflip profile\n");
  load_page_offsets(bitflip_profile1, page_offsets1, offset_pages_map1);

  if(target_address)
    printf("testing on a specific physical page\n");
  else{
    if(random_page){
      //hard coded to only select from page_offset0
      printf("testing on %d random physical pages \n", random_page);
    }
    else{
     printf("need to specific a physical page or enalbe random page testing\n"); 
     return -1;
    }
  }

  //now lets try to test the page offset one by one
  uint64_t mapping_size;
  void* mapping;
  SetupMapping(&mapping_size, &mapping);

  arrange_addresses(mapping, mapping_size, hash_row_pages); 

  //profile using double-sided hammering
  RH_PROFILE_T mod_offsets_freq_XYX;
  RH_PROFILE_T mod_offsets_freq_YYX;
  RH_PROFILE_T mod_offsets_freq_XYY;
  RH_PROFILE_T mod_offsets_freq_YYY;

  RH_PROFILE_T mod_offsets_freq_tg;//target

  std::vector<uint64_t> tested_pages;
  srand(rdtsc());
  // if(!random_page)
  //   tested_pages.push_back(target_address);
  // else{//test multiple random pages
  //   for(int i=0; i<random_page; i++){
  //     size_t the_offset = rand()%page_offsets0.size();
  //     auto iter = std::next(page_offsets0.begin(), the_offset);
  //     uint64_t r_address = iter->first;
  //     tested_pages.push_back(r_address);
  //   }
  // }

  /*create a page that stores a copy of data for the victim 
    row pages (2 in this case)*/
  uint64_t* vic_content_copy = (uint64_t*)malloc(4096);
  uint64_t cp_pa = get_physical_addr((uint64_t)vic_content_copy);
  size_t  cp_hash_set = get_dram_mapping((void*)cp_pa);
  uint64_t cp_row = cp_pa/ROW_SIZE;

  std::map<int, float> batch_leak_rates;
  int total_bits_leaky =0;
  int total_bits_flippable=0;

  int pages_to_test = random_page > 1? random_page : 1;

  int found_pages = 0;
  uint64_t address = target_address;
  //int total_pages_leaky = 0;
  LEAK_PAGE_OFF_T leak_pages_offsets; //page, goal, offset, frequency
  std::map<int, float> bit_leak_rates;

  while(found_pages < pages_to_test){
    //set victim page content
    uint8_t *victim;

    if(target_address){ 
      address = target_address;

      if(!check_page_hammerable(address, &victim)){
        printf("target page 0x%lx not ready for hammering\n", address);
        break;
      }
    }
    else{
      //TODO: note this random address may have been generated before
      address = find_hammerable_page(&victim, goal);
    }

    size_t the_hash_set = get_dram_mapping((void*)address);
    uint64_t the_row = address/ROW_SIZE;

    //avoid the case where the content copy is tampered
    if(cp_row == the_row && cp_hash_set == the_hash_set){
      printf("WARNING: content copy is in the same row with target page 0x%lx\n", address);
      continue;
    }

    /*live template*/
    set_victim_content((uint64_t* )victim, vic_content_copy, goal);

    RH_LEAK_T mode_offset_lt;

    set_content_XYX(the_hash_set, the_row, NULL, goal, false);
    //content of victim would be reinitialized in HammerTargetPages
    HammerTargetPages(&HammerAddressesStandard, (uint64_t*)victim, address,
      number_of_reads, mod_offsets_freq_XYX, vic_content_copy);

    set_content_YYX(the_hash_set, the_row, NULL, goal, false);
    HammerTargetPages(&HammerAddressesStandard, (uint64_t*)victim, address,
      number_of_reads, mod_offsets_freq_YYX, vic_content_copy);

    set_content_XYY(the_hash_set, the_row, NULL, goal, false);
    HammerTargetPages(&HammerAddressesStandard, (uint64_t*)victim, address,
      number_of_reads, mod_offsets_freq_XYY, vic_content_copy);

    set_content_YYY(the_hash_set, the_row, NULL, goal, false);
    HammerTargetPages(&HammerAddressesStandard, (uint64_t*)victim, address,
      number_of_reads, mod_offsets_freq_YYY, vic_content_copy);

    mode_offset_lt = set_leaky_template(mod_offsets_freq_XYX, mod_offsets_freq_YYX, 
      mod_offsets_freq_XYY, mod_offsets_freq_YYY, mod_offsets_freq_tg, goal);

    printf("==>XYX flip profile: ");
    print_flip_template(mod_offsets_freq_XYX, goal);

    printf("==>YYX flip profile: ");
    print_flip_template(mod_offsets_freq_YYX, goal);

    printf("==>XYY flip profile: ");
    print_flip_template(mod_offsets_freq_XYY, goal);

    printf("==>YYY flip profile: ");
    print_flip_template(mod_offsets_freq_YYY, goal);

    printf("==>leaky flip with type profile: ");
    print_leak_template(mode_offset_lt, goal);

    printf("==>Targeted flips for leakage: %lu\n", mod_offsets_freq_tg[goal].size());
    // if(!optimize)
    //   mod_offsets_freq_tg = mod_offsets_freq_XYX;
    print_flip_template(mod_offsets_freq_tg, goal);

    total_bits_flippable += mod_offsets_freq_XYX[goal].size();
    total_bits_leaky += mod_offsets_freq_tg[goal].size();

    mod_offsets_freq_XYX.clear();
    mod_offsets_freq_YYX.clear();
    mod_offsets_freq_XYY.clear();
    mod_offsets_freq_YYY.clear();

    // if(optimize){
    //   //set and test 001 pattern for rows 
    //   set_agg_content(the_hash_set, the_row-1, mod_offsets_freq_101, goal^1, false);
    //   //start hammer
    //   HammerTargetPages(&HammerAddressesStandard, (uint64_t*)victim, address,
    //     number_of_reads, mod_offsets_freq_001, vic_content_copy);  

    //   printf("==>YYX flippable template\n");
    //   print_template(mod_offsets_freq_001);

    //   int flips101 = mod_offsets_freq_101[goal].size();
    //   int flips001 = mod_offsets_freq_001[goal].size();
    //   //remove the flips that appear both in 101 and 001
    //   for(auto entry: mod_offsets_freq_001[goal]){
    //     int page_offset = entry.first;
    //     auto iter = mod_offsets_freq_101[goal].find(page_offset);
    //     if(iter != mod_offsets_freq_101[goal].end()){
    //       printf("delete entry for %d \n", page_offset);
    //       mod_offsets_freq_101[goal].erase(iter);
    //     }
    //   }

    //   printf("==>Page 0x%lx, XYX flippables: %d, YYX flippables: %d, bits to test: %zu\n", address, 
    //     flips101, flips001, mod_offsets_freq_101[goal].size());

    // }
    // else{
    //   printf("==>Page 0x%lx, Total flippables: %zu\n", address, mod_offsets_freq_101[goal].size());

    // }
    
    /*leakage test*/
    if(!mod_offsets_freq_tg[goal].size()){
      printf("Page 0x%lx has no leaky bits to exploit, pass\n", address);
      if(target_address){
        leak_pages_offsets[victim] = mod_offsets_freq_tg;        
        found_pages++;
      }
      
      mod_offsets_freq_tg.clear();
      continue;
    }
    else{
      leak_pages_offsets[victim] = mod_offsets_freq_tg; 
      mod_offsets_freq_tg.clear();
      found_pages++;
    }
  }

  for(int iter=0; iter < per_page_iteration; iter++){
    printf("==>Iteration progress %d/%d\n", iter+1, per_page_iteration);
    /*now test the batch of pages */
    int total_instances = 0;
    int leaked_instances = 0;

    for(auto entry: leak_pages_offsets){    
        //set bit level stripe
        //set_agg_content(the_hash_set, the_row-1, mod_offsets_freq, goal, true);

        //bit flip results under leakage attack
        RH_PROFILE_T mod_offsets_freq_leak;

        uint8_t* one_victim = entry.first;
        uint64_t p_addr = get_physical_addr((uint64_t)one_victim);
        size_t the_hash_set = get_dram_mapping((void*)p_addr);
        uint64_t the_row = p_addr/ROW_SIZE;

        std::map<int, uint8_t> bits_top_agg = set_agg_for_leak(the_hash_set, the_row-1, 
          &entry.second, goal);

        std::map<int, uint8_t> bits_bot_agg = set_agg_content(the_hash_set, the_row+1, 
          &entry.second, goal, true);

        printf("---------------------------\n");
        printf("bits set in top aggressor: ");
        for(auto entry: bits_top_agg){
          printf("(%d, %u) ", entry.first, entry.second);
        }
        printf("\n");

        printf("bits set in bot aggressor: ");
        for(auto entry: bits_bot_agg){
          printf("(%d, %u) ", entry.first, entry.second);
        }
        printf("\n");

        HammerTargetPages(&HammerAddressesStandard, (uint64_t*)one_victim, p_addr, 
        number_of_reads, mod_offsets_freq_leak, vic_content_copy);

        print_flip_template(mod_offsets_freq_leak, goal);
        //now let's count bits leaked:
        int count = count_bits_leaked(bits_top_agg, mod_offsets_freq_leak, goal);
        printf("Bit leakages: %d/%zu for page 0x%lx\n", count, bits_top_agg.size(), p_addr);
        total_instances += bits_top_agg.size();
        leaked_instances += count;

        mod_offsets_freq_leak.clear();
        //set_victim_content((uint64_t* )one_victim, vic_content_copy, goal);
      }

      printf("==>Leaked bits %d and total bits %d in this batch\n", leaked_instances, total_instances);  
      float rate = leaked_instances/(float)total_instances;
      bit_leak_rates[iter] = rate;
      //printf("Total bits for page 0x%lx\n: %.2f%%\n", address, rate);
  }

  printf("Total bits flippable: %d\n", total_bits_flippable);
  printf("Total bits leaky: %d\n", total_bits_leaky);

  for(auto entry: bit_leak_rates){
    printf("Iter %d Rate: %.2f%%\n", entry.first, entry.second*100);  
  }
  
  free((void*)vic_content_copy);
  munmap(mapping, mapping_size);
  printf("finished\n");
}
